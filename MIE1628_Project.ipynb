{"cells":[{"cell_type":"code","source":["# -*- coding: utf-8 -*-\n\"\"\"\n\"\"\"\nimport pandas as pd\npd.core.common.is_list_like = pd.api.types.is_list_like #datareader problem probably fixed in next version of datareader\nfrom pandas_datareader import data as pdr\nimport datetime\nimport pyspark\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.types import *\nimport pyspark.sql.functions as sf\nfrom pyspark.sql.window import Window\nimport numpy as np\nimport fix_yahoo_finance as yf\nfrom math import log"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":1},{"cell_type":"code","source":["yf.pdr_override() # <== that's all it takes :-)\n\n\nstart_date=datetime.date(1980, 12, 12)\nend_date= datetime.date(2018, 1, 1)\n\nstock_list = [\"AAPL\"]\n\nstock_str = \"\"\nfor i in range(len(stock_list)):\n    stock_str  = stock_str + stock_list[i] + \".\"\n\nmain_df = pd.DataFrame()\n\nfor stock in range(len(stock_list)):\n     df = pdr.get_data_yahoo(stock_list[stock], start=start_date, end=end_date)\n     #df.drop(['Close','High', 'Low' , 'Open', 'Volume'], axis=1, inplace=True)\n     df.rename(columns={'Adj Close': 'Adj_close'}, inplace=True)\n     if main_df.empty:\n         main_df = df\n     else:\n        main_df = main_df.join(df) \n           \n#main_df[\"Date\"]=main_df.index\nmain_df.reset_index(level=0, inplace=True)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">\r[                       0%                       ]\r[*********************100%***********************]  1 of 1 downloaded\n</div>"]}}],"execution_count":2},{"cell_type":"code","source":["df = spark.createDataFrame(df)\ndf = df.withColumn(\"ticker\", sf.lit(\"AAPL\"))\ndf.show(10)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">TypeError</span>                                 Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;command-3343521760539920&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">----&gt; 1</span><span class=\"ansiyellow\"> </span>df <span class=\"ansiyellow\">=</span> spark<span class=\"ansiyellow\">.</span>createDataFrame<span class=\"ansiyellow\">(</span>df<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">      2</span> df<span class=\"ansiyellow\">.</span>show<span class=\"ansiyellow\">(</span><span class=\"ansicyan\">10</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/pyspark/sql/session.py</span> in <span class=\"ansicyan\">createDataFrame</span><span class=\"ansiblue\">(self, data, schema, samplingRatio, verifySchema)</span>\n<span class=\"ansigreen\">    725</span>         &quot;&quot;&quot;\n<span class=\"ansigreen\">    726</span>         <span class=\"ansigreen\">if</span> isinstance<span class=\"ansiyellow\">(</span>data<span class=\"ansiyellow\">,</span> DataFrame<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">--&gt; 727</span><span class=\"ansiyellow\">             </span><span class=\"ansigreen\">raise</span> TypeError<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&quot;data is already a DataFrame&quot;</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    728</span> <span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">    729</span>         <span class=\"ansigreen\">if</span> isinstance<span class=\"ansiyellow\">(</span>schema<span class=\"ansiyellow\">,</span> basestring<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansired\">TypeError</span>: data is already a DataFrame</div>"]}}],"execution_count":3},{"cell_type":"code","source":["w = Window().partitionBy(\"ticker\").orderBy(\"date\")\ndf = df.withColumn(\"Log_Adj_Close\", sf.log(\"Adj_close\"))\n\n#Returns\ndf = df.withColumn(\"log_return\", -1* (sf.col(\"Log_Adj_Close\") - sf.lag(\"Log_Adj_Close\", 1).over(w)) / sf.lag(\"Log_Adj_Close\", 5).over(w))\ndf = df.withColumn(\"weekly_log_return\", -1* (sf.col(\"Log_Adj_Close\") - sf.lag(\"Log_Adj_Close\", 5).over(w)) / sf.lag(\"Log_Adj_Close\", 10).over(w))\ndf = df.withColumn(\"biweekly_log_return\", -1* (sf.col(\"Log_Adj_Close\") - sf.lag(\"Log_Adj_Close\", 10).over(w)) / sf.lag(\"Log_Adj_Close\", 21).over(w))\ndf = df.withColumn(\"monthly_log_return\", -1* (sf.col(\"Log_Adj_Close\") - sf.lag(\"Log_Adj_Close\", 21).over(w)) / sf.lag(\"Log_Adj_Close\", 42).over(w))\ndf = df.withColumn(\"bimonthly_log_return\", -1* (sf.col(\"Log_Adj_Close\") - sf.lag(\"Log_Adj_Close\", 42).over(w)) / sf.lag(\"Log_Adj_Close\", 126).over(w))\ndf = df.withColumn(\"annual_log_return\", -1* (sf.col(\"Log_Adj_Close\") - sf.lag(\"Log_Adj_Close\", 252).over(w)) / sf.lag(\"Log_Adj_Close\", 252).over(w))\n\n#Volume\ndf = df.withColumn(\"daily_volume_diff\", (sf.col(\"Volume\") - sf.lag(\"Volume\", 1).over(w))) \ndf = df.withColumn(\"weekly_volume_diff\", (sf.col(\"Volume\") - sf.lag(\"Volume\", 5).over(w))) \ndf = df.withColumn(\"biweekly_volume_diff\", (sf.col(\"Volume\") - sf.lag(\"Volume\", 10).over(w))) \ndf = df.withColumn(\"monthly_volume_diff\", (sf.col(\"Volume\") - sf.lag(\"Volume\", 21).over(w))) \ndf = df.withColumn(\"bimonthly_volume_diff\", (sf.col(\"Volume\") - sf.lag(\"Volume\", 42).over(w))) \ndf = df.withColumn(\"annual_volume_diff\", -1* (sf.col(\"Volume\") - sf.lag(\"Volume\", 252).over(w))) \n\n#Everything else\nw = Window.orderBy('Date').rowsBetween(-5, 0)\ndf = df.withColumn(\"weekly_mean\", sf.avg('log_return').over(w))\ndf = df.withColumn(\"weekly_std\", sf.stddev('log_return').over(w))\ndf = df.withColumn(\"weekly_volume_mean\", sf.avg('Volume').over(w))\ndf = df.withColumn(\"weekly_volume_std\", sf.stddev('Volume').over(w))\n\nw = Window.orderBy('Date').rowsBetween(-10, 0)\ndf = df.withColumn(\"biweekly_mean\", sf.avg('log_return').over(w))\ndf = df.withColumn(\"biweekly_std\", sf.stddev('log_return').over(w))\ndf = df.withColumn(\"biweekly_volume_mean\", sf.avg('Volume').over(w))\ndf = df.withColumn(\"biweekly_volume_std\", sf.stddev('Volume').over(w))\n\nw = Window.orderBy('Date').rowsBetween(-21, 0)\ndf = df.withColumn(\"monthly_mean\", sf.avg('log_return').over(w))\ndf = df.withColumn(\"monthly_std\", sf.stddev('log_return').over(w))\ndf = df.withColumn(\"monthly_volume_mean\", sf.avg('Volume').over(w))\ndf = df.withColumn(\"monthly_volume_std\", sf.stddev('Volume').over(w))\n\nw = Window.orderBy('Date').rowsBetween(-42, 0)\ndf = df.withColumn(\"bimonthly_mean\", sf.avg('log_return').over(w))\ndf = df.withColumn(\"bimonthly_std\", sf.stddev('log_return').over(w))\ndf = df.withColumn(\"bimonthly_volume_mean\", sf.avg('Volume').over(w))\ndf = df.withColumn(\"bimonthly_volume_std\", sf.stddev('Volume').over(w))\n\nw = Window.orderBy('Date').rowsBetween(-126, 0)\ndf = df.withColumn(\"semiannual_mean\", sf.avg('log_return').over(w))\ndf = df.withColumn(\"semiannual_std\", sf.stddev('log_return').over(w))\ndf = df.withColumn(\"semiannual_volume_mean\", sf.avg('Volume').over(w))\ndf = df.withColumn(\"semiannual_volume_std\", sf.stddev('Volume').over(w))\n\nw = Window.orderBy('Date').rowsBetween(-252, 0)\ndf = df.withColumn(\"annual_mean\", sf.avg('log_return').over(w))\ndf = df.withColumn(\"annual_std\", sf.stddev('log_return').over(w))\ndf = df.withColumn(\"annual_volume_mean\", sf.avg('Volume').over(w))\ndf = df.withColumn(\"annual_volume_std\", sf.stddev('Volume').over(w))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":4},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":5}],"metadata":{"name":"MIE1628_Project","notebookId":3343521760539914},"nbformat":4,"nbformat_minor":0}
